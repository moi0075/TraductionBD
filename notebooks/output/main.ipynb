{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f2b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teo\\miniconda3\\envs\\traductionBD\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Main pipeline\n",
    "from ocr import extract_text_from_image,ocr_results_to_dataframe, filter_by_score, cluster_polygons, add_cluster_column, bounding_boxes_by_cluster_with_text\n",
    "from img_tools import get_image_size, save_crops_from_coords, load_image_as_numpy,create_and_save_solid_image,average_grayscale\n",
    "from traduction import ollama_translate_en_fr, translate_cluster_texts\n",
    "from tools import clean_folder, launch_exe, natural_sort_key\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92a480da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dossier ../outputs/ocr_outputs a été nettoyé avec succès.\n",
      "Le dossier ../outputs/text_remove_outputs a été nettoyé avec succès.\n",
      "Le dossier ../outputs/text_drawn_outputs a été nettoyé avec succès.\n"
     ]
    }
   ],
   "source": [
    "clean_folder(\"../outputs/ocr_outputs\")\n",
    "clean_folder(\"../outputs/text_remove_outputs\")\n",
    "clean_folder(\"../outputs/text_drawn_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23459f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_centered_text(image_path, text, font_path, font_size, output_path, margin=10, min_font_size=10, fill_color=(0,0,0)):\n",
    "    \"\"\"\n",
    "    Écrit du texte centré sur une image, avec retour à la ligne automatique.\n",
    "    Ajuste automatiquement la taille de la police si le texte est trop grand.\n",
    "    \n",
    "    Parameters:\n",
    "        fill_color : tuple RGB ou str, couleur du texte (ex: (255,0,0) ou \"red\")\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    max_width = img.width - 2 * margin\n",
    "    max_height = img.height - 2 * margin\n",
    "\n",
    "    # Fonction pour découper le texte en lignes\n",
    "    def split_text_lines(font):\n",
    "        lines = []\n",
    "        for line in text.split('\\n'):\n",
    "            words = line.split()\n",
    "            current_line = \"\"\n",
    "            for word in words:\n",
    "                test_line = current_line + (\" \" if current_line else \"\") + word\n",
    "                bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "                w = bbox[2] - bbox[0]\n",
    "                if w <= max_width:\n",
    "                    current_line = test_line\n",
    "                else:\n",
    "                    if current_line:\n",
    "                        lines.append(current_line)\n",
    "                    current_line = word\n",
    "            if current_line:\n",
    "                lines.append(current_line)\n",
    "        return lines\n",
    "\n",
    "    # Réduire la police si le texte est trop grand\n",
    "    while font_size >= min_font_size:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "        lines = split_text_lines(font)\n",
    "        bbox = draw.textbbox((0, 0), \"Ay\", font=font)\n",
    "        line_height = (bbox[3] - bbox[1]) + 5\n",
    "        total_text_height = line_height * len(lines)\n",
    "\n",
    "        if total_text_height <= max_height:\n",
    "            break\n",
    "        font_size -= 1\n",
    "\n",
    "    # Dessiner le texte centré\n",
    "    y_text = (img.height - total_text_height) // 2\n",
    "    for line in lines:\n",
    "        bbox = draw.textbbox((0, 0), line, font=font)\n",
    "        w = bbox[2] - bbox[0]\n",
    "        x_text = (img.width - w) // 2\n",
    "        draw.text((x_text, y_text), line, font=font, fill=fill_color)\n",
    "        y_text += line_height\n",
    "\n",
    "    img.save(output_path)\n",
    "    print(f\"Image sauvegardée : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c347a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mUsing official model (PP-OCRv5_server_det), the model files will be automatically downloaded and saved in C:\\Users\\teo\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 2413.29it/s]\n",
      "\u001b[32mCreating model: ('latin_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mUsing official model (latin_PP-OCRv5_mobile_rec), the model files will be automatically downloaded and saved in C:\\Users\\teo\\.paddlex\\official_models.\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 1927.38it/s]\n",
      "\u001b[33mResized image size (15383x720) exceeds max_side_limit of 4000. Resizing to fit within limit.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    text     score   x1   y1   x2   y2   x3   y3   x4   y4  cluster\n",
      "0  MURIM  0.998331  131  576  605  586  601  797  126  787        0\n",
      "Cluster 0 sauvegardé : ../outputs/ocr_outputs/cluster_0.png\n",
      "✅ Image sauvegardée ici : ../outputs/text_remove_outputs\\cluster_0.png\n",
      "\n",
      "Cluster 0 original text:\n",
      "MURIM\n",
      "\n",
      "Cluster 0 translated:\n",
      "MURIM\n",
      "\n",
      "   cluster  x_min  y_min  x_max  y_max   text translated translated_upper\n",
      "0        0    126    576    605    797  MURIM      MURIM            MURIM\n",
      "Image sauvegardée : ../outputs/text_drawn_outputs\\cluster_0.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract text from image\n",
    "img_np, factor = load_image_as_numpy(\"../notebooks/ch_0_2.jpg\", None)\n",
    "result = extract_text_from_image(img_np)\n",
    "\n",
    "# Step 2: Convert OCR results to DataFrame\n",
    "df = ocr_results_to_dataframe(result)  \n",
    "df=df.iloc[:1,:]\n",
    "\n",
    "# Step 3: Filter DataFrame by score\n",
    "filtered_df = filter_by_score(df, min_score=0.7)\n",
    "\n",
    "# Step 4 : Cluster the polygons\n",
    "clusters = cluster_polygons(filtered_df, \"x1\",\"y1\",\"x2\",\"y2\",\"x3\",\"y3\",\"x4\",\"y4\", margin_factor=0.1)\n",
    "\n",
    "# Step 5 : Add cluster information to the DataFrame\n",
    "clustered_df = add_cluster_column(filtered_df, clusters)\n",
    "print(clustered_df)\n",
    "\n",
    "# Step 6 : Get bounding boxes for each cluster\n",
    "df_boxes = bounding_boxes_by_cluster_with_text(clustered_df)\n",
    "\n",
    "# Step 7 : Save crops from bounding boxes\n",
    "ocr_outputs_path = \"../outputs/ocr_outputs\"\n",
    "save_crops_from_coords(img_np, df_boxes[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values, ocr_outputs_path,1)\n",
    "\n",
    "# Step 8 : Remove text from img\n",
    "text_remove_path = \"../outputs/text_remove_outputs\"\n",
    "for filename in os.listdir(ocr_outputs_path):\n",
    "    img_path = os.path.join(ocr_outputs_path, filename)\n",
    "    size = get_image_size(img_path)\n",
    "    if average_grayscale(img_path) > 255/2:\n",
    "        create_and_save_solid_image(size[0], size[1], color=(255, 255, 255), save_path=os.path.join(text_remove_path, filename))\n",
    "    else:\n",
    "        create_and_save_solid_image(size[0], size[1], color=(0, 0, 0), save_path=os.path.join(text_remove_path, filename))\n",
    "\n",
    "# Step 9 : Translate the text in each cluster gemma3n:e2b gemma3:12b\n",
    "df_translated = translate_cluster_texts(df_boxes, ollama_translate_en_fr, context=\"Translating dialogues from a webtoon\", model=\"gemma3:12b\")\n",
    "df_translated['translated_upper'] = df_translated['translated'].str.upper()\n",
    "print(df_translated)\n",
    "    \n",
    "# Step 10 : Write translation on img\n",
    "text_drawn_outputs = \"../outputs/text_drawn_outputs\"\n",
    "files = sorted(os.listdir(text_remove_path), key=natural_sort_key)\n",
    "for i, filename in enumerate(files):\n",
    "    img_path = os.path.join(text_remove_path, filename)\n",
    "    text = df_translated[\"translated\"][i]\n",
    "    out_path = os.path.join(text_drawn_outputs, filename)\n",
    "\n",
    "    if average_grayscale(img_path) > 255/2:\n",
    "        fill_color=(0, 0, 0)\n",
    "    else:\n",
    "        fill_color=(255, 255, 255)\n",
    "\n",
    "    draw_centered_text(\n",
    "        image_path=img_path,\n",
    "        text=text,\n",
    "        font_path=\"../inputs/fonts/Komika Text-FontZillion/Fonts/komtxtb_.ttf\",\n",
    "        output_path=out_path,\n",
    "        fill_color=fill_color\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster  x_min  y_min  x_max  y_max   text translated translated_upper\n",
      "0        0    126    576    605    797  MURIM      MURIM            MURIM\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a5351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traductionBD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
